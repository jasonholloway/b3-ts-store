

So now the Committer needs to enforce integrity

for this, it needs a way of evaluating the slice it tries to commit

and whatever does the evalution needs a link to the BlockCache, so it can lazily request committed values out of it
but we don't want the Committer to know all these things

either we supply it with an interpreter of Slices, that can look at a Slice and figure out all previous slices, aggregate them and return
or the (lazy memoised) evaluation is pinned onto the Slice somehow
the pinning OO approach suits, as otherwise there'd be no immediate way of memoising; otherwise we'd have a lookup table for putting aggregations together

--------

So (to recapitulate an old discussion):
Slices should be decorated with per-era evaluations

each time a new era is formed, all slices are re-wrapped so as to provide a nice /evaluate()/ method
this can then be used downstream to figure out exactly what a slice in situ /means/

---

but what of viewing clientside?

then the slices aren't looked at, as there won't be any slices
or rather, slices /will/ be sought, but none will be found

the clientside viewer is of a different paradigm from the per-slice viewings;
it will supply single logs; whereas the evaluations of slices will be holistic

could a logRef be provided to the evaluation?

---

another use-case: server-side out-of-band compression

this will also be per-log (though entire blocks will inevitably be loaded)

the compressor will load entire log histories (or large tranches thereof)
and digest em, presumably with the same evaluation framework

in such case... the compressor will know which choose log to load,
and its blocks will be loaded for it, /into a single slice/

then the evaluator, with its digestive capabilities, will be let loose on it
in fact: if the digestion works across logs (as seems reasonable, delegating to sub evaluators of course)

hmmm, yes, let's leave this for now

as long as what we use now is modular enough to be reused/reformed for this later use, we're a-ok

---------------------

AND SO!

the Committer will, on each slice, be able to evaluate its contents

will this be via subClass of Slice, or by putting the evaluative function in a tuple /within/ the Slice?
I prefer the latter: let's keep subtyping out of this

though: when it come to the combinability of Slices, isn't it the Slice itself we want to shove together?
and doesn't this rely, in turn, on the combinability of its contents?

yes, I think it does. But this is a kind of monoid typeclass: we want all slices to require combinability of its values
but this also means that all arrays and simple values will need wrapping, or at least tampering with

but: we don't want to destructively add numbers, for instance.
nah, combination should be injectable, specificable.

which means, wrapping, really (in the absence of typeclasses)

or - because in practice we're just talking about arrays, it seems we should instead just inject in one place, instead of at each callsite:
whatever is outputting Slices, should just inject in a combine function, suited to the parametised Slice type

----

or - just the digestor, as a distinct phase, could do the combinations
why do they have to be everywhere?

the idea of putting the capability on the data is nice, but it requires an intrusion into the creator of the data
(unless the slice itself had a ctor which required such a combiner - though then this would be specified in multiple places)

better to have a factory in that case that did the wrapping for you

though now the wiring up of the different components becomes all important

----

what happens when combining evaluators?

well: it's pretty easy actually!
the second evaluation just takes the output of the previous

though it'd be more efficient if there wasn't this chaining
(ie composite slices would become less efficient than pristine large slices - which is not scalable behaviour!)

really, the combined evaluator would want to combine its inputs, not chain together outputs to inputs
but the input is almost entirely the Slice range and log values!

range and logParts can be easily combined
but then evaluation is wanted, on a per-slice basis, and with memoisation

there are two cases:
- if the latter is already evaluated, then can we presume that the previous slice has already been combined with? hmm...
  hmm... if we can, then the idea of slices being monoidal evaporates: ie they're already implicitly in a chain;
  the idea that they're free to be rearranged is wishful thinking
  as soon as we get to evaluation, then the chain is implied
  (but if so, then the idea of each slice having its freely-declared range is fanciful too: each slice makes sense only in the whole)

really, then, if the Slice is not to pretend to be something it isn't,
it wouldn't have ranges on at all; these could be calculated when needed from the entire stack of slices, allied with a single stack register
as things are, Slices have memoised tags for ease of use
but these tags give the impression that they're more free than they are...

---

one of the unavoidable things about Slices is that they're ordered
there's always another before, or there's a base

(in passing, the BlockCache itself will in reality just be storing Slices - though without the ranges as ranges are local concerns of the commit mechanism alone)

so, a Slice (as in, an ordered value with a range) /is/ a matter for the commit system; it's not out of the bounds of SliceByEra to furnish these functionalities
though, affixing a function to each and every item of data is wasteful (we could relate to prototypes, but then I fear for our tuplism)

a Slice can be combined, as it's a Slice: this is what Slices do. Their ranges can be shunted together, immutably.
but for a slice to be combinable, its contents need to be combinable to

and this is distinct from digestion of values into simpler ones
which doesn't need to have any knowledge of slices

if combination is immutable, it seems like it shouldn't be on the object too, as this would give primacy to one input over the other, instead of the two of them
being coequals in their combination. A combining function would therefore make most sense

i'm coming to the conclusion that sliceByEra should just dollop out a single slice - ie it should do the combining itself,
saving the work of slice combination for later layers

the era articulation can nicely separate slices for downstream consumers

and the single slice per era setup will also simplify

could the slice be empty? no. better still to dealin sets

but the more that could be bunched together, the better for all downstream operations.

------------------------------

slice unification is an /optimisation/
we don't need it to get our scalable core functionality

the Evaluator and Commiter should always be applied to a /stream/ of slices;
not hard-coded to use just one

which is fine.

---

so we should do other stuff before we whittle on about combinations of slices

in the first instance, we need to aggregate Slices:
how to lazily aggregate them?

the first thought approach was to combine value and evaluator in a tuple
(in fact, the value could be /completely replaced/ by the evaluator: a stream of evaluations)
in fact, I like this interface: certainly the lack of raw updates will be niggly later

dealing just in evaluations focuses in on the combination of evaluations

an evaluation depends on the current value and the previous value
(the concern we did have with the efficiency of piping in results from before goes away if we're going to simplify slices beforehand)

so the stream of evaluations is in fact a reduction over all slices in the era...
each era starts its evaluating afresh

---

the interface in the first place:

it'll be space-wide, and will furnish another function, that will resolve the actual requested log
though: we also want to know the actual logs involved in the slices

the returned value will therefore be a map of log evaluators (or a stream of keyed log evaluators)

if we wanted a real-time representation of errors in our currently-staged updates, we'd want the incremental
adding of log evaluators: each new one in the slice could be subscribed to

----------------------------

getting the evaluator to deal with multiple slices overlaps
with combining slices into one: they both have to come to the same results

on the one hand, the evaluator traverses its inputs
on the other, the inputs join themselves together

we could:
1) always unify before evaluating
2) not bother unifying, just get the evaluator to reduce over the bitty bits

for now, let's do the second, but the first can still be done to optimise 

-------

for efficiency, the thought before was to make log reductions happen only on request,
instead of eagerly reducing everything

somehow the consumer (say, the committer) will have a set of logs to go through as it wishes
well - the per-log reductions are emitted as they're encountered
which achieves the same

so, each sliceEvaluation will emit all of its log entries as potential reductions; but they will only be resolved as needed

so: /evaluate(slice)/
returns /Observable<GroupedObservable<LogRef, View>>/

but not just /View/:
actually, yes, just /View/; or we'd be better calling it /Aggr/

but do we want to pass through each and every update? no! just the one aggregate, thoug asynchronously

So: /evalute(slice): GroupedObservable<LogRef, View>/

but the evaluation will of course not be dispatched exactly like the above:
it's a contextualised operation across a set: i.e. we don't just call it against an individual /Slice/

so it's like /evaluate(slices)/

------------------------------------------------------------


or, howabout, instead of aggregating as part of the reduction,
we just get all of the updates together in the first place,
and aggregate these after

the problem with this is it doesn't broach the issue of memoisation
plus it doesn't make as much use of the slice aggregation as we'd like

---

we need to put aggrs together with updates
into convenient little tuples
ready for scanning together

the base aggr will itself be an Observable, but with a single value
so our scanning of updates in the slice
will be a concatMapping of the base aggr stream

------------------------------------------------------------


but, if the previous Keyed$ is incomplete
then we can never decide that it is missing a certain key, as it might crop up whenever
each slice will continuously merge in, even if nothing has been seen yet

but how can we concat an incomplete stream?
we can't, can we? maybe we could

concatting complete streams is certainly plausible, and would allow us to use concat
to just plonk things together in relative simplicity

new interjections from below require streams to be restated from the beginning
this is basically what eras are doing currently
when new blocks come into the cache, a new era begins

that's one way of doing it
another would be to retain the articulation of blocks and slices through to the end
then the consumer would bear responsibility for traversing this more complicated structure

the using of complete streams alone lets us pass through a simpler structure to be consumed
a kind of pre-digestion: flattening happens sooner, in place. This complicates the upstream components
but also gives them all chance to determine layers of certainty

in reality, all blocks and slices are prone to receive continuing updates
well, blocks are, but not old slices, which /should/ be complete

and if the blocks change, then the era changes; everything on top of the era should be a flat stream

if streams were communicated through as incomplete lumps in an overall, interpretable input,
then the notion of the era dissipates slightly

instead of eras of stability, there'd be a continuing flexible movement
the viewer of a log would itself be reaggregating as new inputs came into its component streams
each sub-aggregation could then be memoised locally and most efficiently reused

the current scheme doesn't grant perfect efficiency of memoisation as we're razing the ground on each era
and beginning afresh
(though the putative viewer would be doing the same if aggregations weren't commutative)

though, having a single era gives a number to an entire space-wide epoch; it synchronises everything and simplifies storage
as we don't then deal with individual per-log indices.

---

the current /Evaluator/ is complicated by the fact in deals in both outputs and inputs, at the same time as trying to match up groupings

the /Committer/ needs to see aggregations of things (and on a per-slice basis!)
so, how would it benefit from just receiving through an articulated stream of updates?

well: there'd still be a pre-aggregation so that both it and the /Viewer/ can use the same partial per-slice aggregations
but: the gathering of a per-log stream of streams would be done beforehand

and then the pre-aggregation could still be done per slice

but then how would we get the memoised partial aggregations to sit on the slices?
if each slice just received the full log history each time?
there is a necessary collocation of computation and data here - they interweave desirably

we're building a system, not a pure structure of information:
a pipeline, not a graph
but the general way is to parse into a local graph; operate on this structure; then re-serialize out intothe lingua franca of our consumers
in a system, however, multiple subcomputations are interleaved
but the lingua franca(s) of these subcomputations should be aligned, so as to simplify the representation of the processing

in the case of our current sub-computation (staging, viewing and committing updates),
the perfect representation of the actual state of things (determining the outputs we wish to see)
would be a stream of streams, articulated with fidelity, ready to be interpreted by our system

but we /already have this/ - in SliceByEra
everything after that is an act of interpretation

--------------------

so, where were we?

in evaluating a slice, because we don't want to re-evaluate for each slice encountered, we must build on the aggregation of the previous slice

but first, we need to split into per-log parts
the issue here is that we're kinda half-treating the aggregation to be space-wide

in fact, this space-wide part of the reduction is precisely the part that should be furninshing (as a separate part of processing) individual per-log reductions

the space wide reduction deals in streams of GroupedObservables with unique keys

so... lets furnish ourselves with per-log reductions first of all

and there was a problem here with prior completions, wasn't there?
nah, what it was, was that we wanted to merge on keyed groupings; but in doing so, we'd have to deal with missing upstream groupings, as a log might be completely new

prior Keyed$<Aggr> would be subscribed to
and if the immediate prior didn't have the key we wanted, it'd also be sucking from its ow prior, so everything available would be offered up

but this means too that the foundational blocklayer would need to be up front in its full set of possible logs
there'd be no lazy querying of the server
instead, each and every log, however small, would appear in the manifest
but the individual stream wouldn't actually be subscribed to until it was needed: this is what would trigger the slow loading of its data

otherwise, a further layer of indirection could be introduced, in that a downstream request for a particularly-addressed log
would have to be sent back down through all the slices, and matched against the accumulated logs of each slice

---------------------


problems:
1) how is concatKeyeds supposed to output things?
   should it output intermediate canned partial objects? yes - the answer has to be yes
   though we can lean on the previous object being final

only when prev$ is complete can we put dummy emptys() in place of actual logs

------

flowing through all keys from below means that for each and every small slice,
all keys will have to be processed

this is inevitable if we are to resolve all keyed logs
but - why do they all have to flow through each and every item?

we don't want to resolve all keyed logs.
well, we do when committing, as we need to know that everything staged makes sense

every single staged updates needs to be eagerly evaluated for this purpose
its output can then be memoised for efficient viewing

but there's a big schism between the needs of the committer with its staged updates
and the big bulk of available, though very lazily evaluated /committed/ updates
eager slices/lazy blocks

as it is, we have a single, simple scheme running through both these disparate zones
what matches the one might not match the other
or - if we want a single scheme, it should be more nuanced to fit

-----

*A more nuanced approach...*

each Slice emits a stream of log keys as advertisement of the logs within it
these let the consumer ask for only the logs it cares about

if the /Committer/ wants to aggregate all the updates in its slice, it just needs to get the list of known logs,
and explicitly ask for keyed logs based on this

the Evaluable will have an /evaluate()/ function that is wired up to previous evaluables
so again, the Committer doesn't need to do it's own looking through slices etc
but it can be selective

the /evaluate()/ stage prepares the slices for viewing and committing - it itself is the interpretation needed by the later layers
also it's an opportunity to memoise (as i keep on saying!)

so no more eager merging together of logs
in fact, the only thing to be received from upstream is an evaluator function


























































































  































































 














